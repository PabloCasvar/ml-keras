{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenador de Gatos y Perros\n",
    "Alan Badillo Salas (badillo.soft@hotmail.com)\n",
    "\n",
    "Este mini-proyecto tiene la intención de crear una red neuronal de tipo CNN, para aprender a determinar si una imagen corresponde a un gato o a un perro.\n",
    "\n",
    "Para más información sobre las redes CNN visita: https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es descargar el archivo zip que contiene 10,000 imágenes de gatos y perros en una resolución de 32x32 pixeles a color. Cada imagen tiene como nombre su identificador. El archivo de imágenes lo puede descargar de http://badillosoft.com/train_cat_dog.zip.\n",
    "\n",
    "Una vez descargado el archivo debemos descomprimirlo y todas las imágenes se encontrarán la carpeta `train_cat_dog`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han importado las librerías necesarias para el análisis\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers, regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Se han importado las librerías necesarias para el análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que cargar el `DataFrame` con los id's de las imágenes y sus etiquetas para utilizarlos en el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    10000 non-null int64\n",
      "id            10000 non-null int64\n",
      "label         10000 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 234.4+ KB\n",
      "None\n",
      "   Unnamed: 0  id label\n",
      "0           9  10   cat\n",
      "1          17  18   cat\n",
      "2          21  22   cat\n",
      "3          26  27   cat\n",
      "4          27  28   dog\n"
     ]
    }
   ],
   "source": [
    "train_cat_dog = pd.read_csv(\"http://badillosoft.com/train_cat_dog.csv\")\n",
    "\n",
    "print(train_cat_dog.info())\n",
    "print(train_cat_dog.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un generador de datos para que tome el `DataFrame` de pandas que contiene los id's de las imágenes y sus etiquetas (`train_cat_dog`). Observa que el generador de datos define que el 20% de ellos serán utilizados para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x11a600510>\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "\n",
    "print(datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el generador de entrenamiento, esto se refiere a un generador que va a cargar las imágenes desde nuestra carpeta basado en el `DataFrame` (`train_cat_dog`) para proveer el `x_train` y el `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"training\",                 # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar vamos a crear un generador de imágenes para las validaciones, esto creará los `x_test` y los `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"validation\",               # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los generadores anteriores, ya podemos alimentar nuestra red CNN. Por lo que, primero debemos crear la CNN como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 17,282\n",
      "Trainable params: 17,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Capas Convolutivas (El filtro/kernel)\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32, 32, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "# Capas Pooling (El reductor)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa Dropout (La pérdida)\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "# Capa Flatten (El aplanador)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Capas de Clasificación (El aprendizaje)\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos el modelo, podemos entrenarlo con los generadores `train_generator` y `test_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.6621 - acc: 0.6024 - val_loss: 0.6456 - val_acc: 0.6396\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 15s 60ms/step - loss: 0.6111 - acc: 0.6654 - val_loss: 0.6085 - val_acc: 0.6733\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 58ms/step - loss: 0.5839 - acc: 0.6841 - val_loss: 0.5885 - val_acc: 0.6860\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 15s 60ms/step - loss: 0.5649 - acc: 0.7020 - val_loss: 0.5941 - val_acc: 0.6748\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 15s 60ms/step - loss: 0.5414 - acc: 0.7243 - val_loss: 0.6198 - val_acc: 0.6585\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.5351 - acc: 0.7271 - val_loss: 0.5897 - val_acc: 0.6794\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.5184 - acc: 0.7408 - val_loss: 0.5745 - val_acc: 0.6951\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.5063 - acc: 0.7480 - val_loss: 0.5910 - val_acc: 0.6890\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.5003 - acc: 0.7540 - val_loss: 0.5779 - val_acc: 0.7119\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.4887 - acc: 0.7668 - val_loss: 0.5904 - val_acc: 0.6972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129467810>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos los tamaños de salto para los kernels\n",
    "STEP_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_TEST = test_generator.n // test_generator.batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,      # Indica quién genera las imágenes de entranamiento\n",
    "    steps_per_epoch=STEP_TRAIN,     # Indica cuántos pasos se realizarán por época\n",
    "    validation_data=test_generator, # Indica el generador de imágenes para la validación\n",
    "    validation_steps=STEP_TEST,     # Indica cuántos pasos se realizarán para la validación\n",
    "    epochs=10                       # Indica las épocas de entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la red CNN ya está entrenada, por lo que medimos su desempeño con las imágenes de validación (`test_generator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.569965748282952, 0.7149390243902439]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(generator=test_generator, steps=STEP_TEST)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el clasificador con imágenes reales\n",
    "\n",
    "Hasta aquí ya hemos entrenado nuestro modelo para aprender a reconocer imágenes de gatos y perros, por lo que podemos ahora descargar una imagen desde internet, reducirla a una resolución de `32x32` pixeles y evaluarla en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2880x3840 at 0x129441890>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "# Python 2\n",
    "from StringIO import StringIO\n",
    "\n",
    "# Gato\n",
    "#url = \"https://www.readersdigest.ca/wp-content/uploads/sites/14/2011/01/4-ways-cheer-up-depressed-cat.jpg\"\n",
    "# Perro\n",
    "#url = \"https://img.huffingtonpost.com/asset/5b7fdeab1900001d035028dc.jpeg?cache=sixpwrbb1s&ops=1910_1000\"\n",
    "# Gato\n",
    "#url = \"https://newsline.com/wp-content/uploads/2018/08/22698/636124053572235005-101816orange-cat-thinkstock.jpg\"\n",
    "# Perro\n",
    "url = \"https://www.guidedogs.org/wp-content/uploads/2018/01/Mobile.jpg\"\n",
    "\n",
    "# Python 2\n",
    "response = requests.get(url)\n",
    "# Python 3\n",
    "# response = request.get(url, stream=True)\n",
    "\n",
    "# Python 2\n",
    "im = Image.open(StringIO(response.content))\n",
    "# Python 3\n",
    "# im = Image.open(response.raw)\n",
    "\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay que reducir la imagen a `32x32` pixeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x129747E10>\n"
     ]
    }
   ],
   "source": [
    "im = im.resize((32, 32), Image.NEAREST)\n",
    "\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos convertir la imagen en un arreglo de números `(32, 32, 3)` y convertirlo a una matriz para que se pueda hacer la predicción. Recordemos que `model.predict` espera una matriz de muestras para hacer la predicción en todas las muestras (no podemos manderle sólo un ejemplo para la predicción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 98 108  39]\n",
      "   [106 112  42]\n",
      "   [ 84  88  29]\n",
      "   ...\n",
      "   [176 159  79]\n",
      "   [167 158  79]\n",
      "   [165 153  81]]\n",
      "\n",
      "  [[135 139  52]\n",
      "   [145 151  55]\n",
      "   [135 141  33]\n",
      "   ...\n",
      "   [149 151  85]\n",
      "   [138 146  86]\n",
      "   [126 129  74]]\n",
      "\n",
      "  [[162 158  59]\n",
      "   [154 157  54]\n",
      "   [154 155  53]\n",
      "   ...\n",
      "   [ 94 113  57]\n",
      "   [104 117  64]\n",
      "   [108 114  66]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 56  74  24]\n",
      "   [ 26  31   1]\n",
      "   [ 36  47   4]\n",
      "   ...\n",
      "   [160 161 165]\n",
      "   [105 104 109]\n",
      "   [ 18  23   1]]\n",
      "\n",
      "  [[ 55  78  26]\n",
      "   [ 49  64  21]\n",
      "   [ 52  61  18]\n",
      "   ...\n",
      "   [136 129 136]\n",
      "   [ 90  89  95]\n",
      "   [ 37  43   5]]\n",
      "\n",
      "  [[ 53  70  16]\n",
      "   [ 38  50  26]\n",
      "   [ 33  55  19]\n",
      "   ...\n",
      "   [  8  20   0]\n",
      "   [ 27  36   7]\n",
      "   [  1   8   1]]]]\n"
     ]
    }
   ],
   "source": [
    "im_array = np.asarray(im)\n",
    "\n",
    "x_test = np.array([im_array]) # np.array([im1, im2, im3, ...])\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos hacer la predicción sobre `x_test`. El resultado nos va a indicar un vector con la probabilidad de que pertenezca a las distintas clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test)\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos dos clases y nos está indicando que tiene una probabilidad `0` de pertenecer a la primer clase y una probabilidad de `1` de pertenecer a la segunda clase. Para ver las clases hacemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'cat': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a tomar las clases y los resultados de la predicción para que imprima que combine los scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog: 1.0\n",
      "cat: 0.0\n"
     ]
    }
   ],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "for label in class_indices:\n",
    "    for score in predict:\n",
    "        index = class_indices[label]\n",
    "        print(\"{}: {}\".format(label, score[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponer una interfaz web y servicios web (API-REST)\n",
    "\n",
    "Finalmente podemos generar mediante flask un servidor que reciba la url de una imagen y nos diga si es perro o si es gato. Así como proveer una página web con una caja y botón que nos diga sobre una url si es gato o si es perro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
