{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenador de Gatos y Perros\n",
    "Alan Badillo Salas (badillo.soft@hotmail.com)\n",
    "\n",
    "Este mini-proyecto tiene la intención de crear una red neuronal de tipo CNN, para aprender a determinar si una imagen corresponde a un gato o a un perro.\n",
    "\n",
    "Para más información sobre las redes CNN visita: https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es descargar el archivo zip que contiene 10,000 imágenes de gatos y perros en una resolución de 32x32 pixeles a color. Cada imagen tiene como nombre su identificador. El archivo de imágenes lo puede descargar de http://badillosoft.com/train_cat_dog.zip.\n",
    "\n",
    "Una vez descargado el archivo debemos descomprimirlo y todas las imágenes se encontrarán la carpeta `train_cat_dog`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han importado las librerías necesarias para el análisis\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers, regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Se han importado las librerías necesarias para el análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que cargar el `DataFrame` con los id's de las imágenes y sus etiquetas para utilizarlos en el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    10000 non-null int64\n",
      "id            10000 non-null int64\n",
      "label         10000 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 234.4+ KB\n",
      "None\n",
      "   Unnamed: 0  id label\n",
      "0           9  10   cat\n",
      "1          17  18   cat\n",
      "2          21  22   cat\n",
      "3          26  27   cat\n",
      "4          27  28   dog\n"
     ]
    }
   ],
   "source": [
    "train_cat_dog = pd.read_csv(\"http://badillosoft.com/train_cat_dog.csv\")\n",
    "\n",
    "print(train_cat_dog.info())\n",
    "print(train_cat_dog.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un generador de datos para que tome el `DataFrame` de pandas que contiene los id's de las imágenes y sus etiquetas (`train_cat_dog`). Observa que el generador de datos define que el 20% de ellos serán utilizados para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x129187a50>\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "\n",
    "print(datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el generador de entrenamiento, esto se refiere a un generador que va a cargar las imágenes desde nuestra carpeta basado en el `DataFrame` (`train_cat_dog`) para proveer el `x_train` y el `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"training\",                 # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar vamos a crear un generador de imágenes para las validaciones, esto creará los `x_test` y los `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"validation\",               # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los generadores anteriores, ya podemos alimentar nuestra red CNN. Por lo que, primero debemos crear la CNN como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 17,282\n",
      "Trainable params: 17,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Capas Convolutivas (El filtro/kernel)\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32, 32, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "# Capas Pooling (El reductor)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa Dropout (La pérdida)\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "# Capa Flatten (El aplanador)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Capas de Clasificación (El aprendizaje)\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos el modelo, podemos entrenarlo con los generadores `train_generator` y `test_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.6637 - acc: 0.5924 - val_loss: 0.6333 - val_acc: 0.6552\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 58ms/step - loss: 0.6185 - acc: 0.6658 - val_loss: 0.6255 - val_acc: 0.6616\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.5873 - acc: 0.6881 - val_loss: 0.5848 - val_acc: 0.6875\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.5657 - acc: 0.7031 - val_loss: 0.6017 - val_acc: 0.6768\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.5358 - acc: 0.7272 - val_loss: 0.6298 - val_acc: 0.6519\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.5294 - acc: 0.7350 - val_loss: 0.5771 - val_acc: 0.7022\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 58ms/step - loss: 0.5122 - acc: 0.7431 - val_loss: 0.5690 - val_acc: 0.7012\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.4966 - acc: 0.7564 - val_loss: 0.5942 - val_acc: 0.6982\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.4894 - acc: 0.7584 - val_loss: 0.5880 - val_acc: 0.6982\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 15s 60ms/step - loss: 0.4760 - acc: 0.7741 - val_loss: 0.5918 - val_acc: 0.7007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119758190>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos los tamaños de salto para los kernels\n",
    "STEP_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_TEST = test_generator.n // test_generator.batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,      # Indica quién genera las imágenes de entranamiento\n",
    "    steps_per_epoch=STEP_TRAIN,     # Indica cuántos pasos se realizarán por época\n",
    "    validation_data=test_generator, # Indica el generador de imágenes para la validación\n",
    "    validation_steps=STEP_TEST,     # Indica cuántos pasos se realizarán para la validación\n",
    "    epochs=10                       # Indica las épocas de entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la red CNN ya está entrenada, por lo que medimos su desempeño con las imágenes de validación (`test_generator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5733478805883144, 0.7149390243902439]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(generator=test_generator, steps=STEP_TEST)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
