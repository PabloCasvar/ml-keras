{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de las flores Iris\n",
    "\n",
    "Las flores Iris son una familia de flores como se describe en https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos.\n",
    "\n",
    "Podemos encontrar la base de datos en formato csv en http://badillosoft.com/iris.csv. La cuál contiene variarias columnas como `sepal length`, `sepal width`, `petal length`, `petal width` y `class`.\n",
    "\n",
    "Las primeras 4 columnas indican características de la flor Iris y la última columna representa la clase (especie) a la que pertenece la flor Iris. Es decir, las primeras 4 columnas serán utilizadas como las entradas para la clasificación y la última columna será utilizada como la salida de la clasificación.\n",
    "\n",
    "Por lo tanto, queremos construir una red neuronal que aprenda a clasificar a qué especie pertenece una flor Iris, dados sus tamaños de sépalo y pétalo y que nos diga a que especie o variedad pertenece.\n",
    "\n",
    "Para conseguirlo debemos entrenar a la red neuronal con los datos reales de la base de datos, siguiendo la norma que 80% de los ejemplos sean para el entrenamiento y 20% de los ejemplos se utilicen para medir el desempeño del aprendizaje. Recordando que en este caso particular los datos vienen ordenados, por lo que antes, tendremos que reordenarlos aleatoriamente para que no haya pérdida de generalidad (si tomamos los primeros 80% de los datos ordenados el 20% restante serían sólo de la clase virgínica por lo que no sería un buen entrenamiento).\n",
    "\n",
    "Además el pre-procesamiento debe incluir una columna extra dónde las clases sean categóricas y no cadenas de texto como vienen los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "     sepal length  sepal width  petal length  petal width           class\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"http://badillosoft.com/iris.csv\")\n",
    "\n",
    "print(df.head(3))\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width        class  especie\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa        1\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa        1\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa        1\n",
      "     sepal length  sepal width  petal length  petal width           class  \\\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica   \n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica   \n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica   \n",
      "\n",
      "     especie  \n",
      "147        3  \n",
      "148        3  \n",
      "149        3  \n"
     ]
    }
   ],
   "source": [
    "df[\"especie\"] = df[\"class\"].map({\n",
    "    \"Iris-setosa\": 1,\n",
    "    \"Iris-versicolor\": 2,\n",
    "    \"Iris-virginica\": 3\n",
    "})\n",
    "\n",
    "print(df.head(3))\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width           class  \\\n",
      "8             4.4          2.9           1.4          0.2     Iris-setosa   \n",
      "103           6.3          2.9           5.6          1.8  Iris-virginica   \n",
      "122           7.7          2.8           6.7          2.0  Iris-virginica   \n",
      "121           5.6          2.8           4.9          2.0  Iris-virginica   \n",
      "13            4.3          3.0           1.1          0.1     Iris-setosa   \n",
      "\n",
      "     especie  \n",
      "8          1  \n",
      "103        3  \n",
      "122        3  \n",
      "121        3  \n",
      "13         1  \n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora tenemos un dataframe con 6 columnas `sepal length`, `sepal width`, `petal length`, `petal width`, `class`, `especie`.\n",
    "\n",
    "Para entrenar una red neuronal necesitamos definir las columnas que serán la entrada de la red, en este caso serán las columnas `sepal length`, `sepal width`, `petal length`, `petal width`. A esta matriz de entrenamiento se le llama el  `x_train`. Recordando que para entrenar la red neuronal necesitamos sólo el 80% de los datos, es decir, si temos `150` datos, necesitamos `0.8 * 150` datos de entrenamiento. El 20% de datos restante será utilizado para medir el desempeño de la red neuronal, a este último conjunto de muestras se le llama `x_test`.\n",
    "\n",
    "Primero recuperamos las columnas que serán utilizadas para el entrenamiento y el desempeño, a estos datos se les conoce como la muestra de entrada `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150 entries, 8 to 124\n",
      "Data columns (total 4 columns):\n",
      "sepal length    150 non-null float64\n",
      "sepal width     150 non-null float64\n",
      "petal length    150 non-null float64\n",
      "petal width     150 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 5.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = df.filter(items=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"])\n",
    "\n",
    "print(x.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego definimos el número de muestras para entrenar, es decir `k = 0.8 * n` donde `n` es el número de total muestras y `k` el 80% de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tomarán 120/150 muestras para el entrenamiento\n"
     ]
    }
   ],
   "source": [
    "n = len(x)\n",
    "k = int(n * 0.8)\n",
    "\n",
    "print(\"Se tomarán {}/{} muestras para el entrenamiento\".format(k, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las primeras `k` muestas del total de muestras y eso es `x_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120 entries, 8 to 17\n",
      "Data columns (total 4 columns):\n",
      "sepal length    120 non-null float64\n",
      "sepal width     120 non-null float64\n",
      "petal length    120 non-null float64\n",
      "petal width     120 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_train = x[:k] # Las primeras 120 muestras desde 0 a 119\n",
    "\n",
    "print(x_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las restantes muestras para medir el desempeño y eso es `x_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 56 to 124\n",
      "Data columns (total 4 columns):\n",
      "sepal length    30 non-null float64\n",
      "sepal width     30 non-null float64\n",
      "petal length    30 non-null float64\n",
      "petal width     30 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_test = x[k:] # Las últimas 30 muestras desde 120 a 149\n",
    "\n",
    "print(x_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos definido las muestras para el entrenamiento (`x_train`) y las muestras para medir el desempeño (`x_test`), ahora debemos obtener los objetivos para el entrenamiento (`y_train`) y los objetivos para medir el desempeño (`y_test`) de forma similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150 entries, 8 to 124\n",
      "Data columns (total 1 columns):\n",
      "especie    150 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.3 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120 entries, 8 to 17\n",
      "Data columns (total 1 columns):\n",
      "especie    120 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.9 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 56 to 124\n",
      "Data columns (total 1 columns):\n",
      "especie    30 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 480.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y = df.filter(items=[\"especie\"])\n",
    "\n",
    "y_train = y[:k]\n",
    "\n",
    "y_test = y[k:]\n",
    "\n",
    "print(y.info())\n",
    "print(y_train.info())\n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos formado las matrices `x_train`, `x_test`, `y_train` y `y_test`. De cuales `x_train` y `y_train` seán utilizadas por la red neuronal para realizar el entrenamiento y `x_test` y `y_test` serán utilizadas para evaluar el desempeño del entrenamiento.\n",
    "\n",
    "Entonces, utilizando Keras crearemos una red neuronal de tipo ANN con la topología `4-8-2-1` con las funciones de activación `Tanh-Tanh-Tanh-ReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x12592b710>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, activation=\"tanh\", input_dim=4))\n",
    "model.add(Dense(8, activation=\"tanh\"))\n",
    "model.add(Dense(2, activation=\"tanh\"))\n",
    "model.add(Dense(1, activation=\"relu\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\", \"categorical_accuracy\"])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos nuestro modelo de la red neuronal ANN podemos entrenar a la red para que ajuste sus pesos mediante `x_train` y `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 313us/step - loss: 0.0395 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 363us/step - loss: 0.0390 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 282us/step - loss: 0.0399 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 271us/step - loss: 0.0390 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 248us/step - loss: 0.0395 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 387us/step - loss: 0.0399 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 342us/step - loss: 0.0390 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 300us/step - loss: 0.0412 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 330us/step - loss: 0.0409 - acc: 0.9750 - categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 276us/step - loss: 0.0395 - acc: 0.9750 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12618dc90>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.values, y_train.values, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que el modelo ya está ajustada (la red neuronal ya aprendió los ejemplos de entrenamiento) podemos medir el desempeño mediante `x_test` y `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 72us/step\n",
      "[0.0059516639448702335, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test.values, y_test.values)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.3 3.3 4.7 1.6] => [2] <> [[2.0526638]]\n",
      "[5.1 3.3 1.7 0.5] => [1] <> [[1.104357]]\n",
      "[7.2 3.6 6.1 2.5] => [3] <> [[2.9728053]]\n",
      "[6.  2.9 4.5 1.5] => [2] <> [[2.1977637]]\n",
      "[4.9 3.1 1.5 0.1] => [1] <> [[1.0708456]]\n",
      "[5.  2.3 3.3 1. ] => [2] <> [[1.7901336]]\n",
      "[5.8 2.8 5.1 2.4] => [3] <> [[3.0285578]]\n",
      "[6.1 3.  4.6 1.4] => [2] <> [[2.0896974]]\n",
      "[6.7 3.1 5.6 2.4] => [3] <> [[3.0079072]]\n",
      "[5.7 4.4 1.5 0.4] => [1] <> [[0.98218316]]\n",
      "[5.2 3.4 1.4 0.2] => [1] <> [[1.0311562]]\n",
      "[5.1 3.5 1.4 0.2] => [1] <> [[1.0164591]]\n",
      "[6.4 3.2 4.5 1.5] => [2] <> [[1.9525874]]\n",
      "[4.6 3.2 1.4 0.2] => [1] <> [[1.0167408]]\n",
      "[5.5 2.4 3.7 1. ] => [2] <> [[1.8654542]]\n",
      "[6.7 3.3 5.7 2.5] => [3] <> [[3.0057142]]\n",
      "[4.6 3.4 1.4 0.3] => [1] <> [[0.9958205]]\n",
      "[7.7 2.6 6.9 2.3] => [3] <> [[3.045065]]\n",
      "[6.8 3.  5.5 2.1] => [3] <> [[2.9348764]]\n",
      "[6.9 3.2 5.7 2.3] => [3] <> [[2.9718678]]\n",
      "[6.7 3.1 4.4 1.4] => [2] <> [[1.8900932]]\n",
      "[7.1 3.  5.9 2.1] => [3] <> [[2.9789279]]\n",
      "[6.5 3.  5.8 2.2] => [3] <> [[3.013321]]\n",
      "[5.1 3.7 1.5 0.4] => [1] <> [[1.0172427]]\n",
      "[6.2 2.9 4.3 1.3] => [2] <> [[1.9407156]]\n",
      "[4.7 3.2 1.3 0.2] => [1] <> [[0.9970692]]\n",
      "[4.6 3.1 1.5 0.2] => [1] <> [[1.0517409]]\n",
      "[6.6 3.  4.4 1.4] => [2] <> [[1.9387356]]\n",
      "[4.8 3.  1.4 0.3] => [1] <> [[1.0457613]]\n",
      "[6.7 3.3 5.7 2.1] => [3] <> [[2.8873072]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    xt = x_test.values[i]\n",
    "    yt = y_test.values[i]\n",
    "    yp = model.predict(np.array([xt]))\n",
    "    print(\"{} => {} <> {}\".format(xt, yt, yp))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
